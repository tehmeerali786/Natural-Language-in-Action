{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 7 - NLPIA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX8wLL8lQrFP"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk8UbZuuRNC6"
      },
      "source": [
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r-L51QYRRk2"
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHQUeIi-RVaF"
      },
      "source": [
        "from keras.layers import Dense, Dropout, Activation"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLwE6JbhRnqU"
      },
      "source": [
        "from keras.layers import Conv1D, GlobalMaxPooling1D"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHWXLtNdSCTE",
        "outputId": "4d198c77-a008-42b4-894f-720d12cfddb0"
      },
      "source": [
        " !wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-05 17:55:49--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  23.5MB/s    in 3.6s    \n",
            "\n",
            "2020-12-05 17:55:53 (22.1 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_dOvpWtEuko"
      },
      "source": [
        "!gzip /content/aclImdb_v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deTif9F0WWTH",
        "outputId": "f209329c-46d2-48ae-b8e5-900b7cddd4e2"
      },
      "source": [
        "!unzip /content/pos2.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/pos2.zip\n",
            "  inflating: pos2/0_9.txt            \n",
            "  inflating: pos2/1_7.txt            \n",
            "  inflating: pos2/10_9.txt           \n",
            "  inflating: pos2/100_7.txt          \n",
            "  inflating: pos2/101_8.txt          \n",
            "  inflating: pos2/102_10.txt         \n",
            "  inflating: pos2/103_7.txt          \n",
            "  inflating: pos2/104_10.txt         \n",
            "  inflating: pos2/105_7.txt          \n",
            "  inflating: pos2/106_10.txt         \n",
            "  inflating: pos2/107_10.txt         \n",
            "  inflating: pos2/108_10.txt         \n",
            "  inflating: pos2/109_10.txt         \n",
            "  inflating: pos2/11_9.txt           \n",
            "  inflating: pos2/110_10.txt         \n",
            "  inflating: pos2/111_10.txt         \n",
            "  inflating: pos2/112_10.txt         \n",
            "  inflating: pos2/113_10.txt         \n",
            "  inflating: pos2/114_10.txt         \n",
            "  inflating: pos2/115_10.txt         \n",
            "  inflating: pos2/116_10.txt         \n",
            "  inflating: pos2/117_10.txt         \n",
            "  inflating: pos2/118_8.txt          \n",
            "  inflating: pos2/119_10.txt         \n",
            "  inflating: pos2/12_9.txt           \n",
            "  inflating: pos2/120_8.txt          \n",
            "  inflating: pos2/121_10.txt         \n",
            "  inflating: pos2/122_9.txt          \n",
            "  inflating: pos2/123_10.txt         \n",
            "  inflating: pos2/124_10.txt         \n",
            "  inflating: pos2/125_7.txt          \n",
            "  inflating: pos2/126_10.txt         \n",
            "  inflating: pos2/127_7.txt          \n",
            "  inflating: pos2/128_7.txt          \n",
            "  inflating: pos2/129_9.txt          \n",
            "  inflating: pos2/13_7.txt           \n",
            "  inflating: pos2/130_9.txt          \n",
            "  inflating: pos2/131_10.txt         \n",
            "  inflating: pos2/132_9.txt          \n",
            "  inflating: pos2/133_10.txt         \n",
            "  inflating: pos2/134_10.txt         \n",
            "  inflating: pos2/135_7.txt          \n",
            "  inflating: pos2/136_10.txt         \n",
            "  inflating: pos2/137_7.txt          \n",
            "  inflating: pos2/138_7.txt          \n",
            "  inflating: pos2/139_10.txt         \n",
            "  inflating: pos2/14_10.txt          \n",
            "  inflating: pos2/140_8.txt          \n",
            "  inflating: pos2/141_9.txt          \n",
            "  inflating: pos2/142_8.txt          \n",
            "  inflating: pos2/143_7.txt          \n",
            "  inflating: pos2/144_8.txt          \n",
            "  inflating: pos2/145_10.txt         \n",
            "  inflating: pos2/146_10.txt         \n",
            "  inflating: pos2/147_9.txt          \n",
            "  inflating: pos2/148_9.txt          \n",
            "  inflating: pos2/149_10.txt         \n",
            "  inflating: pos2/15_7.txt           \n",
            "  inflating: pos2/150_8.txt          \n",
            "  inflating: pos2/151_10.txt         \n",
            "  inflating: pos2/152_9.txt          \n",
            "  inflating: pos2/153_10.txt         \n",
            "  inflating: pos2/154_8.txt          \n",
            "  inflating: pos2/155_10.txt         \n",
            "  inflating: pos2/156_8.txt          \n",
            "  inflating: pos2/157_9.txt          \n",
            "  inflating: pos2/158_10.txt         \n",
            "  inflating: pos2/159_10.txt         \n",
            "  inflating: pos2/16_7.txt           \n",
            "  inflating: pos2/160_9.txt          \n",
            "  inflating: pos2/161_8.txt          \n",
            "  inflating: pos2/162_8.txt          \n",
            "  inflating: pos2/163_10.txt         \n",
            "  inflating: pos2/164_10.txt         \n",
            "  inflating: pos2/165_7.txt          \n",
            "  inflating: pos2/166_7.txt          \n",
            "  inflating: pos2/167_7.txt          \n",
            "  inflating: pos2/168_9.txt          \n",
            "  inflating: pos2/169_8.txt          \n",
            "  inflating: pos2/17_9.txt           \n",
            "  inflating: pos2/170_10.txt         \n",
            "  inflating: pos2/171_8.txt          \n",
            "  inflating: pos2/172_10.txt         \n",
            "  inflating: pos2/173_7.txt          \n",
            "  inflating: pos2/174_7.txt          \n",
            "  inflating: pos2/175_7.txt          \n",
            "  inflating: pos2/176_7.txt          \n",
            "  inflating: pos2/177_9.txt          \n",
            "  inflating: pos2/178_7.txt          \n",
            "  inflating: pos2/179_8.txt          \n",
            "  inflating: pos2/18_7.txt           \n",
            "  inflating: pos2/180_9.txt          \n",
            "  inflating: pos2/181_10.txt         \n",
            "  inflating: pos2/182_10.txt         \n",
            "  inflating: pos2/183_8.txt          \n",
            "  inflating: pos2/184_8.txt          \n",
            "  inflating: pos2/185_9.txt          \n",
            "  inflating: pos2/186_8.txt          \n",
            "  inflating: pos2/187_8.txt          \n",
            "  inflating: pos2/188_7.txt          \n",
            "  inflating: pos2/189_9.txt          \n",
            "  inflating: pos2/19_10.txt          \n",
            "  inflating: pos2/190_10.txt         \n",
            "  inflating: pos2/191_9.txt          \n",
            "  inflating: pos2/192_9.txt          \n",
            "  inflating: pos2/193_7.txt          \n",
            "  inflating: pos2/194_8.txt          \n",
            "  inflating: pos2/195_8.txt          \n",
            "  inflating: pos2/196_9.txt          \n",
            "  inflating: pos2/197_9.txt          \n",
            "  inflating: pos2/198_8.txt          \n",
            "  inflating: pos2/199_10.txt         \n",
            "  inflating: pos2/2_9.txt            \n",
            "  inflating: pos2/20_9.txt           \n",
            "  inflating: pos2/200_10.txt         \n",
            "  inflating: pos2/201_10.txt         \n",
            "  inflating: pos2/202_10.txt         \n",
            "  inflating: pos2/203_7.txt          \n",
            "  inflating: pos2/204_10.txt         \n",
            "  inflating: pos2/205_8.txt          \n",
            "  inflating: pos2/206_10.txt         \n",
            "  inflating: pos2/207_8.txt          \n",
            "  inflating: pos2/208_9.txt          \n",
            "  inflating: pos2/209_8.txt          \n",
            "  inflating: pos2/21_7.txt           \n",
            "  inflating: pos2/210_10.txt         \n",
            "  inflating: pos2/211_9.txt          \n",
            "  inflating: pos2/212_9.txt          \n",
            "  inflating: pos2/213_9.txt          \n",
            "  inflating: pos2/214_7.txt          \n",
            "  inflating: pos2/215_8.txt          \n",
            "  inflating: pos2/216_8.txt          \n",
            "  inflating: pos2/217_8.txt          \n",
            "  inflating: pos2/218_9.txt          \n",
            "  inflating: pos2/219_8.txt          \n",
            "  inflating: pos2/22_8.txt           \n",
            "  inflating: pos2/220_10.txt         \n",
            "  inflating: pos2/221_9.txt          \n",
            "  inflating: pos2/222_10.txt         \n",
            "  inflating: pos2/223_9.txt          \n",
            "  inflating: pos2/224_10.txt         \n",
            "  inflating: pos2/225_9.txt          \n",
            "  inflating: pos2/226_10.txt         \n",
            "  inflating: pos2/227_10.txt         \n",
            "  inflating: pos2/228_7.txt          \n",
            "  inflating: pos2/229_10.txt         \n",
            "  inflating: pos2/23_7.txt           \n",
            "  inflating: pos2/230_9.txt          \n",
            "  inflating: pos2/231_10.txt         \n",
            "  inflating: pos2/232_10.txt         \n",
            "  inflating: pos2/233_7.txt          \n",
            "  inflating: pos2/234_10.txt         \n",
            "  inflating: pos2/235_10.txt         \n",
            "  inflating: pos2/236_9.txt          \n",
            "  inflating: pos2/237_10.txt         \n",
            "  inflating: pos2/238_10.txt         \n",
            "  inflating: pos2/239_7.txt          \n",
            "  inflating: pos2/24_8.txt           \n",
            "  inflating: pos2/240_10.txt         \n",
            "  inflating: pos2/241_8.txt          \n",
            "  inflating: pos2/242_8.txt          \n",
            "  inflating: pos2/243_10.txt         \n",
            "  inflating: pos2/244_10.txt         \n",
            "  inflating: pos2/245_9.txt          \n",
            "  inflating: pos2/246_7.txt          \n",
            "  inflating: pos2/247_10.txt         \n",
            "  inflating: pos2/248_10.txt         \n",
            "  inflating: pos2/249_10.txt         \n",
            "  inflating: pos2/25_7.txt           \n",
            "  inflating: pos2/250_7.txt          \n",
            "  inflating: pos2/251_10.txt         \n",
            "  inflating: pos2/252_9.txt          \n",
            "  inflating: pos2/253_7.txt          \n",
            "  inflating: pos2/254_8.txt          \n",
            "  inflating: pos2/255_10.txt         \n",
            "  inflating: pos2/256_9.txt          \n",
            "  inflating: pos2/257_7.txt          \n",
            "  inflating: pos2/258_7.txt          \n",
            "  inflating: pos2/259_8.txt          \n",
            "  inflating: pos2/26_9.txt           \n",
            "  inflating: pos2/260_7.txt          \n",
            "  inflating: pos2/261_8.txt          \n",
            "  inflating: pos2/262_8.txt          \n",
            "  inflating: pos2/263_9.txt          \n",
            "  inflating: pos2/264_7.txt          \n",
            "  inflating: pos2/265_7.txt          \n",
            "  inflating: pos2/266_7.txt          \n",
            "  inflating: pos2/267_7.txt          \n",
            "  inflating: pos2/268_8.txt          \n",
            "  inflating: pos2/269_8.txt          \n",
            "  inflating: pos2/27_10.txt          \n",
            "  inflating: pos2/270_10.txt         \n",
            "  inflating: pos2/271_10.txt         \n",
            "  inflating: pos2/272_10.txt         \n",
            "  inflating: pos2/273_9.txt          \n",
            "  inflating: pos2/274_7.txt          \n",
            "  inflating: pos2/275_10.txt         \n",
            "  inflating: pos2/276_10.txt         \n",
            "  inflating: pos2/277_8.txt          \n",
            "  inflating: pos2/278_9.txt          \n",
            "  inflating: pos2/279_9.txt          \n",
            "  inflating: pos2/28_10.txt          \n",
            "  inflating: pos2/280_8.txt          \n",
            "  inflating: pos2/281_10.txt         \n",
            "  inflating: pos2/282_9.txt          \n",
            "  inflating: pos2/283_8.txt          \n",
            "  inflating: pos2/284_10.txt         \n",
            "  inflating: pos2/285_10.txt         \n",
            "  inflating: pos2/286_10.txt         \n",
            "  inflating: pos2/287_9.txt          \n",
            "  inflating: pos2/288_10.txt         \n",
            "  inflating: pos2/289_10.txt         \n",
            "  inflating: pos2/29_10.txt          \n",
            "  inflating: pos2/290_9.txt          \n",
            "  inflating: pos2/291_10.txt         \n",
            "  inflating: pos2/292_10.txt         \n",
            "  inflating: pos2/293_7.txt          \n",
            "  inflating: pos2/294_10.txt         \n",
            "  inflating: pos2/295_10.txt         \n",
            "  inflating: pos2/296_10.txt         \n",
            "  inflating: pos2/297_10.txt         \n",
            "  inflating: pos2/298_8.txt          \n",
            "  inflating: pos2/299_10.txt         \n",
            "  inflating: pos2/3_10.txt           \n",
            "  inflating: pos2/30_7.txt           \n",
            "  inflating: pos2/300_9.txt          \n",
            "  inflating: pos2/301_10.txt         \n",
            "  inflating: pos2/302_10.txt         \n",
            "  inflating: pos2/303_10.txt         \n",
            "  inflating: pos2/304_10.txt         \n",
            "  inflating: pos2/305_8.txt          \n",
            "  inflating: pos2/306_10.txt         \n",
            "  inflating: pos2/307_8.txt          \n",
            "  inflating: pos2/308_8.txt          \n",
            "  inflating: pos2/309_9.txt          \n",
            "  inflating: pos2/31_8.txt           \n",
            "  inflating: pos2/310_7.txt          \n",
            "  inflating: pos2/311_9.txt          \n",
            "  inflating: pos2/312_10.txt         \n",
            "  inflating: pos2/313_10.txt         \n",
            "  inflating: pos2/314_10.txt         \n",
            "  inflating: pos2/315_10.txt         \n",
            "  inflating: pos2/316_10.txt         \n",
            "  inflating: pos2/317_10.txt         \n",
            "  inflating: pos2/318_10.txt         \n",
            "  inflating: pos2/319_9.txt          \n",
            "  inflating: pos2/32_10.txt          \n",
            "  inflating: pos2/320_8.txt          \n",
            "  inflating: pos2/321_10.txt         \n",
            "  inflating: pos2/322_10.txt         \n",
            "  inflating: pos2/323_10.txt         \n",
            "  inflating: pos2/324_8.txt          \n",
            "  inflating: pos2/325_9.txt          \n",
            "  inflating: pos2/326_10.txt         \n",
            "  inflating: pos2/327_8.txt          \n",
            "  inflating: pos2/328_10.txt         \n",
            "  inflating: pos2/329_10.txt         \n",
            "  inflating: pos2/33_7.txt           \n",
            "  inflating: pos2/330_10.txt         \n",
            "  inflating: pos2/331_10.txt         \n",
            "  inflating: pos2/332_10.txt         \n",
            "  inflating: pos2/333_10.txt         \n",
            "  inflating: pos2/334_10.txt         \n",
            "  inflating: pos2/335_10.txt         \n",
            "  inflating: pos2/336_10.txt         \n",
            "  inflating: pos2/337_9.txt          \n",
            "  inflating: pos2/338_10.txt         \n",
            "  inflating: pos2/339_10.txt         \n",
            "  inflating: pos2/34_8.txt           \n",
            "  inflating: pos2/340_10.txt         \n",
            "  inflating: pos2/341_10.txt         \n",
            "  inflating: pos2/342_10.txt         \n",
            "  inflating: pos2/343_10.txt         \n",
            "  inflating: pos2/344_8.txt          \n",
            "  inflating: pos2/345_7.txt          \n",
            "  inflating: pos2/346_10.txt         \n",
            "  inflating: pos2/347_10.txt         \n",
            "  inflating: pos2/348_7.txt          \n",
            "  inflating: pos2/349_10.txt         \n",
            "  inflating: pos2/35_8.txt           \n",
            "  inflating: pos2/350_9.txt          \n",
            "  inflating: pos2/351_10.txt         \n",
            "  inflating: pos2/352_10.txt         \n",
            "  inflating: pos2/353_9.txt          \n",
            "  inflating: pos2/354_9.txt          \n",
            "  inflating: pos2/355_9.txt          \n",
            "  inflating: pos2/356_10.txt         \n",
            "  inflating: pos2/357_10.txt         \n",
            "  inflating: pos2/358_10.txt         \n",
            "  inflating: pos2/359_8.txt          \n",
            "  inflating: pos2/36_10.txt          \n",
            "  inflating: pos2/360_10.txt         \n",
            "  inflating: pos2/361_10.txt         \n",
            "  inflating: pos2/362_10.txt         \n",
            "  inflating: pos2/363_10.txt         \n",
            "  inflating: pos2/364_10.txt         \n",
            "  inflating: pos2/365_10.txt         \n",
            "  inflating: pos2/366_9.txt          \n",
            "  inflating: pos2/367_10.txt         \n",
            "  inflating: pos2/368_10.txt         \n",
            "  inflating: pos2/369_10.txt         \n",
            "  inflating: pos2/37_9.txt           \n",
            "  inflating: pos2/370_10.txt         \n",
            "  inflating: pos2/371_9.txt          \n",
            "  inflating: pos2/372_10.txt         \n",
            "  inflating: pos2/373_10.txt         \n",
            "  inflating: pos2/374_10.txt         \n",
            "  inflating: pos2/375_9.txt          \n",
            "  inflating: pos2/376_10.txt         \n",
            "  inflating: pos2/377_7.txt          \n",
            "  inflating: pos2/378_8.txt          \n",
            "  inflating: pos2/379_10.txt         \n",
            "  inflating: pos2/38_10.txt          \n",
            "  inflating: pos2/380_10.txt         \n",
            "  inflating: pos2/381_10.txt         \n",
            "  inflating: pos2/382_10.txt         \n",
            "  inflating: pos2/383_10.txt         \n",
            "  inflating: pos2/384_8.txt          \n",
            "  inflating: pos2/385_10.txt         \n",
            "  inflating: pos2/386_7.txt          \n",
            "  inflating: pos2/387_8.txt          \n",
            "  inflating: pos2/388_8.txt          \n",
            "  inflating: pos2/389_10.txt         \n",
            "  inflating: pos2/39_9.txt           \n",
            "  inflating: pos2/390_10.txt         \n",
            "  inflating: pos2/391_8.txt          \n",
            "  inflating: pos2/392_9.txt          \n",
            "  inflating: pos2/393_8.txt          \n",
            "  inflating: pos2/394_8.txt          \n",
            "  inflating: pos2/395_10.txt         \n",
            "  inflating: pos2/396_8.txt          \n",
            "  inflating: pos2/397_9.txt          \n",
            "  inflating: pos2/398_10.txt         \n",
            "  inflating: pos2/399_9.txt          \n",
            "  inflating: pos2/4_8.txt            \n",
            "  inflating: pos2/40_8.txt           \n",
            "  inflating: pos2/400_10.txt         \n",
            "  inflating: pos2/401_10.txt         \n",
            "  inflating: pos2/402_10.txt         \n",
            "  inflating: pos2/403_8.txt          \n",
            "  inflating: pos2/404_9.txt          \n",
            "  inflating: pos2/405_10.txt         \n",
            "  inflating: pos2/406_8.txt          \n",
            "  inflating: pos2/407_10.txt         \n",
            "  inflating: pos2/408_10.txt         \n",
            "  inflating: pos2/409_10.txt         \n",
            "  inflating: pos2/41_9.txt           \n",
            "  inflating: pos2/410_8.txt          \n",
            "  inflating: pos2/411_10.txt         \n",
            "  inflating: pos2/412_8.txt          \n",
            "  inflating: pos2/413_10.txt         \n",
            "  inflating: pos2/414_10.txt         \n",
            "  inflating: pos2/415_7.txt          \n",
            "  inflating: pos2/416_8.txt          \n",
            "  inflating: pos2/417_7.txt          \n",
            "  inflating: pos2/418_9.txt          \n",
            "  inflating: pos2/419_7.txt          \n",
            "  inflating: pos2/42_10.txt          \n",
            "  inflating: pos2/420_7.txt          \n",
            "  inflating: pos2/421_9.txt          \n",
            "  inflating: pos2/422_7.txt          \n",
            "  inflating: pos2/423_10.txt         \n",
            "  inflating: pos2/424_8.txt          \n",
            "  inflating: pos2/425_10.txt         \n",
            "  inflating: pos2/426_7.txt          \n",
            "  inflating: pos2/427_10.txt         \n",
            "  inflating: pos2/428_7.txt          \n",
            "  inflating: pos2/429_10.txt         \n",
            "  inflating: pos2/43_10.txt          \n",
            "  inflating: pos2/430_7.txt          \n",
            "  inflating: pos2/431_8.txt          \n",
            "  inflating: pos2/432_8.txt          \n",
            "  inflating: pos2/433_10.txt         \n",
            "  inflating: pos2/434_8.txt          \n",
            "  inflating: pos2/435_8.txt          \n",
            "  inflating: pos2/436_10.txt         \n",
            "  inflating: pos2/437_9.txt          \n",
            "  inflating: pos2/438_9.txt          \n",
            "  inflating: pos2/439_9.txt          \n",
            "  inflating: pos2/44_8.txt           \n",
            "  inflating: pos2/440_10.txt         \n",
            "  inflating: pos2/441_9.txt          \n",
            "  inflating: pos2/442_9.txt          \n",
            "  inflating: pos2/443_10.txt         \n",
            "  inflating: pos2/444_10.txt         \n",
            "  inflating: pos2/445_10.txt         \n",
            "  inflating: pos2/446_10.txt         \n",
            "  inflating: pos2/447_10.txt         \n",
            "  inflating: pos2/448_10.txt         \n",
            "  inflating: pos2/449_10.txt         \n",
            "  inflating: pos2/45_10.txt          \n",
            "  inflating: pos2/450_10.txt         \n",
            "  inflating: pos2/451_10.txt         \n",
            "  inflating: pos2/452_10.txt         \n",
            "  inflating: pos2/453_10.txt         \n",
            "  inflating: pos2/454_8.txt          \n",
            "  inflating: pos2/455_10.txt         \n",
            "  inflating: pos2/456_10.txt         \n",
            "  inflating: pos2/457_10.txt         \n",
            "  inflating: pos2/458_10.txt         \n",
            "  inflating: pos2/459_10.txt         \n",
            "  inflating: pos2/46_9.txt           \n",
            "  inflating: pos2/460_9.txt          \n",
            "  inflating: pos2/461_8.txt          \n",
            "  inflating: pos2/462_8.txt          \n",
            "  inflating: pos2/463_7.txt          \n",
            "  inflating: pos2/464_10.txt         \n",
            "  inflating: pos2/465_10.txt         \n",
            "  inflating: pos2/466_8.txt          \n",
            "  inflating: pos2/467_7.txt          \n",
            "  inflating: pos2/468_7.txt          \n",
            "  inflating: pos2/469_7.txt          \n",
            "  inflating: pos2/47_8.txt           \n",
            "  inflating: pos2/470_10.txt         \n",
            "  inflating: pos2/471_7.txt          \n",
            "  inflating: pos2/472_10.txt         \n",
            "  inflating: pos2/473_9.txt          \n",
            "  inflating: pos2/474_7.txt          \n",
            "  inflating: pos2/475_10.txt         \n",
            "  inflating: pos2/476_7.txt          \n",
            "  inflating: pos2/477_10.txt         \n",
            "  inflating: pos2/478_7.txt          \n",
            "  inflating: pos2/479_10.txt         \n",
            "  inflating: pos2/48_7.txt           \n",
            "  inflating: pos2/480_10.txt         \n",
            "  inflating: pos2/481_10.txt         \n",
            "  inflating: pos2/482_8.txt          \n",
            "  inflating: pos2/483_8.txt          \n",
            "  inflating: pos2/484_8.txt          \n",
            "  inflating: pos2/485_8.txt          \n",
            "  inflating: pos2/486_9.txt          \n",
            "  inflating: pos2/487_8.txt          \n",
            "  inflating: pos2/488_9.txt          \n",
            "  inflating: pos2/489_7.txt          \n",
            "  inflating: pos2/49_10.txt          \n",
            "  inflating: pos2/490_9.txt          \n",
            "  inflating: pos2/491_7.txt          \n",
            "  inflating: pos2/492_7.txt          \n",
            "  inflating: pos2/493_10.txt         \n",
            "  inflating: pos2/494_9.txt          \n",
            "  inflating: pos2/495_7.txt          \n",
            "  inflating: pos2/496_10.txt         \n",
            "  inflating: pos2/497_10.txt         \n",
            "  inflating: pos2/498_10.txt         \n",
            "  inflating: pos2/499_8.txt          \n",
            "  inflating: pos2/5_10.txt           \n",
            "  inflating: pos2/50_10.txt          \n",
            "  inflating: pos2/500_9.txt          \n",
            "  inflating: pos2/51_10.txt          \n",
            "  inflating: pos2/52_10.txt          \n",
            "  inflating: pos2/53_10.txt          \n",
            "  inflating: pos2/54_10.txt          \n",
            "  inflating: pos2/55_9.txt           \n",
            "  inflating: pos2/56_10.txt          \n",
            "  inflating: pos2/57_10.txt          \n",
            "  inflating: pos2/58_9.txt           \n",
            "  inflating: pos2/59_7.txt           \n",
            "  inflating: pos2/6_10.txt           \n",
            "  inflating: pos2/60_8.txt           \n",
            "  inflating: pos2/61_10.txt          \n",
            "  inflating: pos2/62_10.txt          \n",
            "  inflating: pos2/63_10.txt          \n",
            "  inflating: pos2/64_7.txt           \n",
            "  inflating: pos2/65_10.txt          \n",
            "  inflating: pos2/66_8.txt           \n",
            "  inflating: pos2/67_10.txt          \n",
            "  inflating: pos2/68_10.txt          \n",
            "  inflating: pos2/69_10.txt          \n",
            "  inflating: pos2/7_7.txt            \n",
            "  inflating: pos2/70_9.txt           \n",
            "  inflating: pos2/71_10.txt          \n",
            "  inflating: pos2/72_7.txt           \n",
            "  inflating: pos2/73_7.txt           \n",
            "  inflating: pos2/74_8.txt           \n",
            "  inflating: pos2/75_8.txt           \n",
            "  inflating: pos2/76_7.txt           \n",
            "  inflating: pos2/77_7.txt           \n",
            "  inflating: pos2/78_10.txt          \n",
            "  inflating: pos2/79_10.txt          \n",
            "  inflating: pos2/8_7.txt            \n",
            "  inflating: pos2/80_9.txt           \n",
            "  inflating: pos2/81_10.txt          \n",
            "  inflating: pos2/82_8.txt           \n",
            "  inflating: pos2/83_10.txt          \n",
            "  inflating: pos2/84_10.txt          \n",
            "  inflating: pos2/85_10.txt          \n",
            "  inflating: pos2/86_10.txt          \n",
            "  inflating: pos2/87_10.txt          \n",
            "  inflating: pos2/88_9.txt           \n",
            "  inflating: pos2/89_7.txt           \n",
            "  inflating: pos2/9_7.txt            \n",
            "  inflating: pos2/90_7.txt           \n",
            "  inflating: pos2/91_8.txt           \n",
            "  inflating: pos2/92_9.txt           \n",
            "  inflating: pos2/93_10.txt          \n",
            "  inflating: pos2/94_10.txt          \n",
            "  inflating: pos2/95_10.txt          \n",
            "  inflating: pos2/96_10.txt          \n",
            "  inflating: pos2/97_9.txt           \n",
            "  inflating: pos2/98_10.txt          \n",
            "  inflating: pos2/99_8.txt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8BrlIqnWnBc",
        "outputId": "3fda9a3c-8c71-41d0-be60-1f9309723735"
      },
      "source": [
        "!unzip /content/neg2.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/neg2.zip\n",
            "  inflating: neg2/0_3.txt            \n",
            "  inflating: neg2/1_1.txt            \n",
            "  inflating: neg2/10_2.txt           \n",
            "  inflating: neg2/100_3.txt          \n",
            "  inflating: neg2/101_1.txt          \n",
            "  inflating: neg2/102_1.txt          \n",
            "  inflating: neg2/103_1.txt          \n",
            "  inflating: neg2/104_3.txt          \n",
            "  inflating: neg2/105_2.txt          \n",
            "  inflating: neg2/106_2.txt          \n",
            "  inflating: neg2/107_2.txt          \n",
            "  inflating: neg2/108_1.txt          \n",
            "  inflating: neg2/109_2.txt          \n",
            "  inflating: neg2/11_3.txt           \n",
            "  inflating: neg2/110_1.txt          \n",
            "  inflating: neg2/111_4.txt          \n",
            "  inflating: neg2/112_1.txt          \n",
            "  inflating: neg2/113_4.txt          \n",
            "  inflating: neg2/114_4.txt          \n",
            "  inflating: neg2/115_2.txt          \n",
            "  inflating: neg2/116_1.txt          \n",
            "  inflating: neg2/117_3.txt          \n",
            "  inflating: neg2/118_2.txt          \n",
            "  inflating: neg2/119_4.txt          \n",
            "  inflating: neg2/12_1.txt           \n",
            "  inflating: neg2/120_1.txt          \n",
            "  inflating: neg2/121_4.txt          \n",
            "  inflating: neg2/122_1.txt          \n",
            "  inflating: neg2/123_1.txt          \n",
            "  inflating: neg2/124_2.txt          \n",
            "  inflating: neg2/125_1.txt          \n",
            "  inflating: neg2/126_1.txt          \n",
            "  inflating: neg2/127_4.txt          \n",
            "  inflating: neg2/128_4.txt          \n",
            "  inflating: neg2/129_3.txt          \n",
            "  inflating: neg2/13_2.txt           \n",
            "  inflating: neg2/130_1.txt          \n",
            "  inflating: neg2/131_4.txt          \n",
            "  inflating: neg2/132_3.txt          \n",
            "  inflating: neg2/133_2.txt          \n",
            "  inflating: neg2/134_2.txt          \n",
            "  inflating: neg2/135_4.txt          \n",
            "  inflating: neg2/136_4.txt          \n",
            "  inflating: neg2/137_4.txt          \n",
            "  inflating: neg2/138_4.txt          \n",
            "  inflating: neg2/139_4.txt          \n",
            "  inflating: neg2/14_2.txt           \n",
            "  inflating: neg2/140_2.txt          \n",
            "  inflating: neg2/141_3.txt          \n",
            "  inflating: neg2/142_3.txt          \n",
            "  inflating: neg2/143_2.txt          \n",
            "  inflating: neg2/144_2.txt          \n",
            "  inflating: neg2/145_2.txt          \n",
            "  inflating: neg2/146_2.txt          \n",
            "  inflating: neg2/147_4.txt          \n",
            "  inflating: neg2/148_2.txt          \n",
            "  inflating: neg2/149_1.txt          \n",
            "  inflating: neg2/15_1.txt           \n",
            "  inflating: neg2/150_1.txt          \n",
            "  inflating: neg2/151_1.txt          \n",
            "  inflating: neg2/152_4.txt          \n",
            "  inflating: neg2/153_1.txt          \n",
            "  inflating: neg2/154_3.txt          \n",
            "  inflating: neg2/155_3.txt          \n",
            "  inflating: neg2/156_1.txt          \n",
            "  inflating: neg2/157_1.txt          \n",
            "  inflating: neg2/158_3.txt          \n",
            "  inflating: neg2/159_4.txt          \n",
            "  inflating: neg2/16_3.txt           \n",
            "  inflating: neg2/160_2.txt          \n",
            "  inflating: neg2/161_2.txt          \n",
            "  inflating: neg2/162_4.txt          \n",
            "  inflating: neg2/163_4.txt          \n",
            "  inflating: neg2/164_3.txt          \n",
            "  inflating: neg2/165_4.txt          \n",
            "  inflating: neg2/166_1.txt          \n",
            "  inflating: neg2/167_1.txt          \n",
            "  inflating: neg2/168_1.txt          \n",
            "  inflating: neg2/169_1.txt          \n",
            "  inflating: neg2/17_3.txt           \n",
            "  inflating: neg2/170_1.txt          \n",
            "  inflating: neg2/171_1.txt          \n",
            "  inflating: neg2/172_1.txt          \n",
            "  inflating: neg2/173_3.txt          \n",
            "  inflating: neg2/174_3.txt          \n",
            "  inflating: neg2/175_1.txt          \n",
            "  inflating: neg2/176_4.txt          \n",
            "  inflating: neg2/177_1.txt          \n",
            "  inflating: neg2/178_3.txt          \n",
            "  inflating: neg2/179_3.txt          \n",
            "  inflating: neg2/18_3.txt           \n",
            "  inflating: neg2/180_4.txt          \n",
            "  inflating: neg2/181_2.txt          \n",
            "  inflating: neg2/182_1.txt          \n",
            "  inflating: neg2/183_3.txt          \n",
            "  inflating: neg2/184_2.txt          \n",
            "  inflating: neg2/185_4.txt          \n",
            "  inflating: neg2/186_1.txt          \n",
            "  inflating: neg2/187_2.txt          \n",
            "  inflating: neg2/188_1.txt          \n",
            "  inflating: neg2/189_1.txt          \n",
            "  inflating: neg2/19_4.txt           \n",
            "  inflating: neg2/190_1.txt          \n",
            "  inflating: neg2/191_3.txt          \n",
            "  inflating: neg2/192_2.txt          \n",
            "  inflating: neg2/193_1.txt          \n",
            "  inflating: neg2/194_1.txt          \n",
            "  inflating: neg2/195_4.txt          \n",
            "  inflating: neg2/196_3.txt          \n",
            "  inflating: neg2/197_3.txt          \n",
            "  inflating: neg2/198_2.txt          \n",
            "  inflating: neg2/199_1.txt          \n",
            "  inflating: neg2/2_1.txt            \n",
            "  inflating: neg2/20_1.txt           \n",
            "  inflating: neg2/200_1.txt          \n",
            "  inflating: neg2/201_4.txt          \n",
            "  inflating: neg2/202_2.txt          \n",
            "  inflating: neg2/203_1.txt          \n",
            "  inflating: neg2/204_4.txt          \n",
            "  inflating: neg2/205_4.txt          \n",
            "  inflating: neg2/206_2.txt          \n",
            "  inflating: neg2/207_1.txt          \n",
            "  inflating: neg2/208_1.txt          \n",
            "  inflating: neg2/209_1.txt          \n",
            "  inflating: neg2/21_4.txt           \n",
            "  inflating: neg2/210_4.txt          \n",
            "  inflating: neg2/211_4.txt          \n",
            "  inflating: neg2/212_4.txt          \n",
            "  inflating: neg2/213_4.txt          \n",
            "  inflating: neg2/214_4.txt          \n",
            "  inflating: neg2/215_4.txt          \n",
            "  inflating: neg2/216_4.txt          \n",
            "  inflating: neg2/217_3.txt          \n",
            "  inflating: neg2/218_4.txt          \n",
            "  inflating: neg2/219_2.txt          \n",
            "  inflating: neg2/22_1.txt           \n",
            "  inflating: neg2/220_4.txt          \n",
            "  inflating: neg2/221_4.txt          \n",
            "  inflating: neg2/222_1.txt          \n",
            "  inflating: neg2/223_1.txt          \n",
            "  inflating: neg2/224_4.txt          \n",
            "  inflating: neg2/225_2.txt          \n",
            "  inflating: neg2/226_4.txt          \n",
            "  inflating: neg2/227_1.txt          \n",
            "  inflating: neg2/228_1.txt          \n",
            "  inflating: neg2/229_1.txt          \n",
            "  inflating: neg2/23_3.txt           \n",
            "  inflating: neg2/230_2.txt          \n",
            "  inflating: neg2/231_1.txt          \n",
            "  inflating: neg2/232_1.txt          \n",
            "  inflating: neg2/233_1.txt          \n",
            "  inflating: neg2/234_1.txt          \n",
            "  inflating: neg2/235_1.txt          \n",
            "  inflating: neg2/236_1.txt          \n",
            "  inflating: neg2/237_1.txt          \n",
            "  inflating: neg2/238_4.txt          \n",
            "  inflating: neg2/239_2.txt          \n",
            "  inflating: neg2/24_1.txt           \n",
            "  inflating: neg2/240_1.txt          \n",
            "  inflating: neg2/241_1.txt          \n",
            "  inflating: neg2/242_1.txt          \n",
            "  inflating: neg2/243_3.txt          \n",
            "  inflating: neg2/244_4.txt          \n",
            "  inflating: neg2/245_1.txt          \n",
            "  inflating: neg2/246_3.txt          \n",
            "  inflating: neg2/247_3.txt          \n",
            "  inflating: neg2/248_4.txt          \n",
            "  inflating: neg2/249_3.txt          \n",
            "  inflating: neg2/25_1.txt           \n",
            "  inflating: neg2/250_3.txt          \n",
            "  inflating: neg2/251_3.txt          \n",
            "  inflating: neg2/252_4.txt          \n",
            "  inflating: neg2/253_3.txt          \n",
            "  inflating: neg2/254_1.txt          \n",
            "  inflating: neg2/255_3.txt          \n",
            "  inflating: neg2/256_1.txt          \n",
            "  inflating: neg2/257_2.txt          \n",
            "  inflating: neg2/258_4.txt          \n",
            "  inflating: neg2/259_3.txt          \n",
            "  inflating: neg2/26_3.txt           \n",
            "  inflating: neg2/260_4.txt          \n",
            "  inflating: neg2/261_4.txt          \n",
            "  inflating: neg2/262_4.txt          \n",
            "  inflating: neg2/263_4.txt          \n",
            "  inflating: neg2/264_2.txt          \n",
            "  inflating: neg2/265_1.txt          \n",
            "  inflating: neg2/266_3.txt          \n",
            "  inflating: neg2/267_3.txt          \n",
            "  inflating: neg2/268_1.txt          \n",
            "  inflating: neg2/269_1.txt          \n",
            "  inflating: neg2/27_1.txt           \n",
            "  inflating: neg2/270_1.txt          \n",
            "  inflating: neg2/271_1.txt          \n",
            "  inflating: neg2/272_2.txt          \n",
            "  inflating: neg2/273_1.txt          \n",
            "  inflating: neg2/274_2.txt          \n",
            "  inflating: neg2/275_3.txt          \n",
            "  inflating: neg2/276_2.txt          \n",
            "  inflating: neg2/277_4.txt          \n",
            "  inflating: neg2/278_1.txt          \n",
            "  inflating: neg2/279_1.txt          \n",
            "  inflating: neg2/28_2.txt           \n",
            "  inflating: neg2/280_2.txt          \n",
            "  inflating: neg2/281_1.txt          \n",
            "  inflating: neg2/282_1.txt          \n",
            "  inflating: neg2/283_1.txt          \n",
            "  inflating: neg2/284_2.txt          \n",
            "  inflating: neg2/285_3.txt          \n",
            "  inflating: neg2/286_1.txt          \n",
            "  inflating: neg2/287_4.txt          \n",
            "  inflating: neg2/288_1.txt          \n",
            "  inflating: neg2/289_3.txt          \n",
            "  inflating: neg2/29_4.txt           \n",
            "  inflating: neg2/290_2.txt          \n",
            "  inflating: neg2/291_3.txt          \n",
            "  inflating: neg2/292_1.txt          \n",
            "  inflating: neg2/293_2.txt          \n",
            "  inflating: neg2/294_4.txt          \n",
            "  inflating: neg2/295_3.txt          \n",
            "  inflating: neg2/296_2.txt          \n",
            "  inflating: neg2/297_4.txt          \n",
            "  inflating: neg2/298_4.txt          \n",
            "  inflating: neg2/299_1.txt          \n",
            "  inflating: neg2/3_4.txt            \n",
            "  inflating: neg2/30_1.txt           \n",
            "  inflating: neg2/300_4.txt          \n",
            "  inflating: neg2/301_1.txt          \n",
            "  inflating: neg2/302_4.txt          \n",
            "  inflating: neg2/303_2.txt          \n",
            "  inflating: neg2/304_4.txt          \n",
            "  inflating: neg2/305_1.txt          \n",
            "  inflating: neg2/306_1.txt          \n",
            "  inflating: neg2/307_1.txt          \n",
            "  inflating: neg2/308_1.txt          \n",
            "  inflating: neg2/309_1.txt          \n",
            "  inflating: neg2/31_1.txt           \n",
            "  inflating: neg2/310_1.txt          \n",
            "  inflating: neg2/311_1.txt          \n",
            "  inflating: neg2/312_2.txt          \n",
            "  inflating: neg2/313_2.txt          \n",
            "  inflating: neg2/314_1.txt          \n",
            "  inflating: neg2/315_1.txt          \n",
            "  inflating: neg2/316_1.txt          \n",
            "  inflating: neg2/317_1.txt          \n",
            "  inflating: neg2/318_1.txt          \n",
            "  inflating: neg2/319_1.txt          \n",
            "  inflating: neg2/32_3.txt           \n",
            "  inflating: neg2/320_1.txt          \n",
            "  inflating: neg2/321_1.txt          \n",
            "  inflating: neg2/322_1.txt          \n",
            "  inflating: neg2/323_1.txt          \n",
            "  inflating: neg2/324_1.txt          \n",
            "  inflating: neg2/325_2.txt          \n",
            "  inflating: neg2/326_1.txt          \n",
            "  inflating: neg2/327_3.txt          \n",
            "  inflating: neg2/328_1.txt          \n",
            "  inflating: neg2/329_1.txt          \n",
            "  inflating: neg2/33_3.txt           \n",
            "  inflating: neg2/330_1.txt          \n",
            "  inflating: neg2/331_1.txt          \n",
            "  inflating: neg2/332_1.txt          \n",
            "  inflating: neg2/333_3.txt          \n",
            "  inflating: neg2/334_4.txt          \n",
            "  inflating: neg2/335_4.txt          \n",
            "  inflating: neg2/336_1.txt          \n",
            "  inflating: neg2/337_4.txt          \n",
            "  inflating: neg2/338_4.txt          \n",
            "  inflating: neg2/339_4.txt          \n",
            "  inflating: neg2/34_1.txt           \n",
            "  inflating: neg2/340_3.txt          \n",
            "  inflating: neg2/341_4.txt          \n",
            "  inflating: neg2/342_1.txt          \n",
            "  inflating: neg2/343_2.txt          \n",
            "  inflating: neg2/344_2.txt          \n",
            "  inflating: neg2/345_4.txt          \n",
            "  inflating: neg2/346_1.txt          \n",
            "  inflating: neg2/347_1.txt          \n",
            "  inflating: neg2/348_2.txt          \n",
            "  inflating: neg2/349_4.txt          \n",
            "  inflating: neg2/35_3.txt           \n",
            "  inflating: neg2/350_2.txt          \n",
            "  inflating: neg2/351_4.txt          \n",
            "  inflating: neg2/352_4.txt          \n",
            "  inflating: neg2/353_4.txt          \n",
            "  inflating: neg2/354_3.txt          \n",
            "  inflating: neg2/355_4.txt          \n",
            "  inflating: neg2/356_4.txt          \n",
            "  inflating: neg2/357_2.txt          \n",
            "  inflating: neg2/358_4.txt          \n",
            "  inflating: neg2/359_3.txt          \n",
            "  inflating: neg2/36_4.txt           \n",
            "  inflating: neg2/360_4.txt          \n",
            "  inflating: neg2/361_4.txt          \n",
            "  inflating: neg2/362_3.txt          \n",
            "  inflating: neg2/363_1.txt          \n",
            "  inflating: neg2/364_1.txt          \n",
            "  inflating: neg2/365_1.txt          \n",
            "  inflating: neg2/366_1.txt          \n",
            "  inflating: neg2/367_2.txt          \n",
            "  inflating: neg2/368_4.txt          \n",
            "  inflating: neg2/369_1.txt          \n",
            "  inflating: neg2/37_3.txt           \n",
            "  inflating: neg2/370_1.txt          \n",
            "  inflating: neg2/371_1.txt          \n",
            "  inflating: neg2/372_1.txt          \n",
            "  inflating: neg2/373_4.txt          \n",
            "  inflating: neg2/374_2.txt          \n",
            "  inflating: neg2/375_2.txt          \n",
            "  inflating: neg2/376_4.txt          \n",
            "  inflating: neg2/377_1.txt          \n",
            "  inflating: neg2/378_4.txt          \n",
            "  inflating: neg2/379_2.txt          \n",
            "  inflating: neg2/38_2.txt           \n",
            "  inflating: neg2/380_4.txt          \n",
            "  inflating: neg2/381_1.txt          \n",
            "  inflating: neg2/382_1.txt          \n",
            "  inflating: neg2/383_4.txt          \n",
            "  inflating: neg2/384_4.txt          \n",
            "  inflating: neg2/385_3.txt          \n",
            "  inflating: neg2/386_4.txt          \n",
            "  inflating: neg2/387_2.txt          \n",
            "  inflating: neg2/388_1.txt          \n",
            "  inflating: neg2/389_3.txt          \n",
            "  inflating: neg2/39_2.txt           \n",
            "  inflating: neg2/390_4.txt          \n",
            "  inflating: neg2/391_4.txt          \n",
            "  inflating: neg2/392_3.txt          \n",
            "  inflating: neg2/393_2.txt          \n",
            "  inflating: neg2/394_3.txt          \n",
            "  inflating: neg2/395_1.txt          \n",
            "  inflating: neg2/396_3.txt          \n",
            "  inflating: neg2/397_3.txt          \n",
            "  inflating: neg2/398_3.txt          \n",
            "  inflating: neg2/399_2.txt          \n",
            "  inflating: neg2/4_4.txt            \n",
            "  inflating: neg2/40_3.txt           \n",
            "  inflating: neg2/400_2.txt          \n",
            "  inflating: neg2/401_3.txt          \n",
            "  inflating: neg2/402_2.txt          \n",
            "  inflating: neg2/403_3.txt          \n",
            "  inflating: neg2/404_2.txt          \n",
            "  inflating: neg2/405_3.txt          \n",
            "  inflating: neg2/406_2.txt          \n",
            "  inflating: neg2/407_4.txt          \n",
            "  inflating: neg2/408_2.txt          \n",
            "  inflating: neg2/409_2.txt          \n",
            "  inflating: neg2/41_1.txt           \n",
            "  inflating: neg2/410_4.txt          \n",
            "  inflating: neg2/411_2.txt          \n",
            "  inflating: neg2/412_4.txt          \n",
            "  inflating: neg2/413_3.txt          \n",
            "  inflating: neg2/414_2.txt          \n",
            "  inflating: neg2/415_3.txt          \n",
            "  inflating: neg2/416_4.txt          \n",
            "  inflating: neg2/417_1.txt          \n",
            "  inflating: neg2/418_4.txt          \n",
            "  inflating: neg2/419_2.txt          \n",
            "  inflating: neg2/42_3.txt           \n",
            "  inflating: neg2/420_4.txt          \n",
            "  inflating: neg2/421_4.txt          \n",
            "  inflating: neg2/422_1.txt          \n",
            "  inflating: neg2/423_4.txt          \n",
            "  inflating: neg2/424_4.txt          \n",
            "  inflating: neg2/425_2.txt          \n",
            "  inflating: neg2/426_3.txt          \n",
            "  inflating: neg2/427_4.txt          \n",
            "  inflating: neg2/428_1.txt          \n",
            "  inflating: neg2/429_3.txt          \n",
            "  inflating: neg2/43_4.txt           \n",
            "  inflating: neg2/430_1.txt          \n",
            "  inflating: neg2/431_4.txt          \n",
            "  inflating: neg2/432_4.txt          \n",
            "  inflating: neg2/433_4.txt          \n",
            "  inflating: neg2/434_4.txt          \n",
            "  inflating: neg2/435_2.txt          \n",
            "  inflating: neg2/436_1.txt          \n",
            "  inflating: neg2/437_4.txt          \n",
            "  inflating: neg2/438_4.txt          \n",
            "  inflating: neg2/439_1.txt          \n",
            "  inflating: neg2/44_2.txt           \n",
            "  inflating: neg2/440_3.txt          \n",
            "  inflating: neg2/441_2.txt          \n",
            "  inflating: neg2/442_1.txt          \n",
            "  inflating: neg2/443_3.txt          \n",
            "  inflating: neg2/444_4.txt          \n",
            "  inflating: neg2/445_4.txt          \n",
            "  inflating: neg2/446_3.txt          \n",
            "  inflating: neg2/447_1.txt          \n",
            "  inflating: neg2/448_1.txt          \n",
            "  inflating: neg2/449_4.txt          \n",
            "  inflating: neg2/45_2.txt           \n",
            "  inflating: neg2/450_1.txt          \n",
            "  inflating: neg2/451_2.txt          \n",
            "  inflating: neg2/452_3.txt          \n",
            "  inflating: neg2/453_3.txt          \n",
            "  inflating: neg2/454_4.txt          \n",
            "  inflating: neg2/455_4.txt          \n",
            "  inflating: neg2/456_1.txt          \n",
            "  inflating: neg2/457_3.txt          \n",
            "  inflating: neg2/458_1.txt          \n",
            "  inflating: neg2/459_1.txt          \n",
            "  inflating: neg2/46_4.txt           \n",
            "  inflating: neg2/460_2.txt          \n",
            "  inflating: neg2/461_1.txt          \n",
            "  inflating: neg2/462_2.txt          \n",
            "  inflating: neg2/463_4.txt          \n",
            "  inflating: neg2/464_2.txt          \n",
            "  inflating: neg2/465_1.txt          \n",
            "  inflating: neg2/466_1.txt          \n",
            "  inflating: neg2/467_1.txt          \n",
            "  inflating: neg2/468_4.txt          \n",
            "  inflating: neg2/469_2.txt          \n",
            "  inflating: neg2/47_2.txt           \n",
            "  inflating: neg2/470_3.txt          \n",
            "  inflating: neg2/471_4.txt          \n",
            "  inflating: neg2/472_1.txt          \n",
            "  inflating: neg2/473_1.txt          \n",
            "  inflating: neg2/474_4.txt          \n",
            "  inflating: neg2/475_1.txt          \n",
            "  inflating: neg2/476_1.txt          \n",
            "  inflating: neg2/477_4.txt          \n",
            "  inflating: neg2/478_2.txt          \n",
            "  inflating: neg2/479_3.txt          \n",
            "  inflating: neg2/48_4.txt           \n",
            "  inflating: neg2/480_3.txt          \n",
            "  inflating: neg2/481_3.txt          \n",
            "  inflating: neg2/482_1.txt          \n",
            "  inflating: neg2/483_2.txt          \n",
            "  inflating: neg2/484_1.txt          \n",
            "  inflating: neg2/485_3.txt          \n",
            "  inflating: neg2/486_1.txt          \n",
            "  inflating: neg2/487_4.txt          \n",
            "  inflating: neg2/488_4.txt          \n",
            "  inflating: neg2/489_4.txt          \n",
            "  inflating: neg2/49_4.txt           \n",
            "  inflating: neg2/490_3.txt          \n",
            "  inflating: neg2/491_1.txt          \n",
            "  inflating: neg2/492_4.txt          \n",
            "  inflating: neg2/493_4.txt          \n",
            "  inflating: neg2/494_3.txt          \n",
            "  inflating: neg2/495_1.txt          \n",
            "  inflating: neg2/496_1.txt          \n",
            "  inflating: neg2/497_2.txt          \n",
            "  inflating: neg2/498_3.txt          \n",
            "  inflating: neg2/499_1.txt          \n",
            "  inflating: neg2/5_3.txt            \n",
            "  inflating: neg2/50_4.txt           \n",
            "  inflating: neg2/500_2.txt          \n",
            "  inflating: neg2/51_1.txt           \n",
            "  inflating: neg2/52_1.txt           \n",
            "  inflating: neg2/53_3.txt           \n",
            "  inflating: neg2/54_1.txt           \n",
            "  inflating: neg2/55_1.txt           \n",
            "  inflating: neg2/56_3.txt           \n",
            "  inflating: neg2/57_4.txt           \n",
            "  inflating: neg2/58_3.txt           \n",
            "  inflating: neg2/59_3.txt           \n",
            "  inflating: neg2/6_1.txt            \n",
            "  inflating: neg2/60_4.txt           \n",
            "  inflating: neg2/61_3.txt           \n",
            "  inflating: neg2/62_2.txt           \n",
            "  inflating: neg2/63_1.txt           \n",
            "  inflating: neg2/64_1.txt           \n",
            "  inflating: neg2/65_4.txt           \n",
            "  inflating: neg2/66_4.txt           \n",
            "  inflating: neg2/67_2.txt           \n",
            "  inflating: neg2/68_2.txt           \n",
            "  inflating: neg2/69_4.txt           \n",
            "  inflating: neg2/7_3.txt            \n",
            "  inflating: neg2/70_2.txt           \n",
            "  inflating: neg2/71_1.txt           \n",
            "  inflating: neg2/72_4.txt           \n",
            "  inflating: neg2/73_1.txt           \n",
            "  inflating: neg2/74_3.txt           \n",
            "  inflating: neg2/75_1.txt           \n",
            "  inflating: neg2/76_3.txt           \n",
            "  inflating: neg2/77_4.txt           \n",
            "  inflating: neg2/78_4.txt           \n",
            "  inflating: neg2/79_4.txt           \n",
            "  inflating: neg2/8_4.txt            \n",
            "  inflating: neg2/80_3.txt           \n",
            "  inflating: neg2/81_1.txt           \n",
            "  inflating: neg2/82_1.txt           \n",
            "  inflating: neg2/83_3.txt           \n",
            "  inflating: neg2/84_3.txt           \n",
            "  inflating: neg2/85_2.txt           \n",
            "  inflating: neg2/86_4.txt           \n",
            "  inflating: neg2/87_4.txt           \n",
            "  inflating: neg2/88_2.txt           \n",
            "  inflating: neg2/89_2.txt           \n",
            "  inflating: neg2/9_1.txt            \n",
            "  inflating: neg2/90_4.txt           \n",
            "  inflating: neg2/91_1.txt           \n",
            "  inflating: neg2/92_3.txt           \n",
            "  inflating: neg2/93_1.txt           \n",
            "  inflating: neg2/94_1.txt           \n",
            "  inflating: neg2/95_3.txt           \n",
            "  inflating: neg2/96_1.txt           \n",
            "  inflating: neg2/97_1.txt           \n",
            "  inflating: neg2/98_1.txt           \n",
            "  inflating: neg2/99_1.txt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1zzMGbeeKFP"
      },
      "source": [
        "import glob"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxMz0CfMePtu"
      },
      "source": [
        "import os"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKPRVXJ8eRTu"
      },
      "source": [
        "from random import shuffle"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9PtKCu4eVXz"
      },
      "source": [
        "def pre_process_data(filepath):\n",
        "  \"\"\"\n",
        "    This is dependent on your training data source but we will try to generalize it as best as possible\n",
        "  \"\"\"\n",
        "  positive_path = os.path.join(filepath, 'pos2')\n",
        "  negative_path = os.path.join(filepath, 'neg2')\n",
        "\n",
        "  pos_label = 1\n",
        "  neg_label = 0\n",
        "\n",
        "  dataset = []\n",
        "\n",
        "  for filename in glob.glob(os.path.join(positive_path, '*.txt')):\n",
        "    with open(filename, 'r') as f:\n",
        "      dataset.append((pos_label, f.read()))\n",
        "\n",
        "  for filename in glob.glob(os.path.join(negative_path, '*.txt')):\n",
        "    with open(filename, 'r') as f:\n",
        "      dataset.append((neg_label, f.read()))\n",
        "\n",
        "  shuffle(dataset)\n",
        "\n",
        "  return dataset\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Xj-UvGjmIg"
      },
      "source": [
        "dataset = pre_process_data(\"/content/\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW64NWDvkOcB",
        "outputId": "540a0b11-9b6e-4080-9436-354850e1602f"
      },
      "source": [
        "print(dataset[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 'As a psychiatrist specialized in trauma, I find this film a beautiful shown example of a severe psychic trauma, even a trauma. It not only explains the enormous difficulties those people have to cope wither, but that even love is sometimes not enough. But she tries!')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG_tM2b4uv_5",
        "outputId": "ae3a617c-dc65-48b3-824f-4e4e8bc05373"
      },
      "source": [
        "!pip install nlpia"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nlpia in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from nlpia) (4.2.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from nlpia) (0.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from nlpia) (0.22.2.post1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from nlpia) (2.2.4)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from nlpia) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from nlpia) (2.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nlpia) (4.41.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from nlpia) (0.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from nlpia) (3.2.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nlpia) (2019.12.20)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from nlpia) (2.3.0)\n",
            "Requirement already satisfied: html2text in /usr/local/lib/python3.6/dist-packages (from nlpia) (2020.1.16)\n",
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (from nlpia) (0.9.0)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.6/dist-packages (from nlpia) (0.12.0)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from nlpia) (1.0.1)\n",
            "Requirement already satisfied: pugnlp in /usr/local/lib/python3.6/dist-packages (from nlpia) (0.2.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from nlpia) (3.2.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from nlpia) (4.4.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from nlpia) (1.0.0)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.6/dist-packages (from nlpia) (1.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from nlpia) (3.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nlpia) (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->nlpia) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->nlpia) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->nlpia) (0.17.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (2.0.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (1.0.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (1.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->nlpia) (50.3.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->nlpia) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->nlpia) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nlpia) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nlpia) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nlpia) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->nlpia) (2.4.7)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (0.35.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (0.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (3.12.4)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (1.6.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->nlpia) (1.33.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->nlpia) (0.5.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from pugnlp->nlpia) (4.0.1)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.6/dist-packages (from pugnlp->nlpia) (0.18.0)\n",
            "Requirement already satisfied: coverage in /usr/local/lib/python3.6/dist-packages (from pugnlp->nlpia) (3.7.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from pugnlp->nlpia) (19.3.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->nlpia) (1.3.3)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (5.0.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (7.5.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->nlpia) (5.3.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->nlpia) (3.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->nlpia) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->nlpia) (2.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->nlpia) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->nlpia) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->nlpia) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->nlpia) (2020.11.8)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->nlpia) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->nlpia) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->nlpia) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->nlpia) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->nlpia) (1.17.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->pugnlp->nlpia) (1.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nlpia) (4.7.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nlpia) (2.6.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nlpia) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nlpia) (5.3.5)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nlpia) (4.3.3)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nlpia) (20.0.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nlpia) (1.9.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (0.6.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (3.2.1)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (2.11.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (0.8.4)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nlpia) (5.0.8)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->nlpia) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->nlpia) (3.5.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->nlpia) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->nlpia) (1.0.18)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nlpia) (0.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nlpia) (1.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->nlpia) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->nlpia) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->nlpia) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->nlpia) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->nlpia) (0.2.8)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets->qtconsole->jupyter->nlpia) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->nlpia) (20.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter->nlpia) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter->nlpia) (2.6.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->nlpia) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->nlpia) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->nlpia) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->nlpia) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->nlpia) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->nlpia) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->nlpia) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW_Sw2e0kSwk"
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "2Adg6pYNuz-g",
        "outputId": "0283c169-e6e9-434f-ee02-21d31a6fb0ee"
      },
      "source": [
        "word_vectors = get_data('w2v', limit=200000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 402111/402111 [00:28<00:00, 14009.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-05 18:03:45,357 WARNING:  nlpia.loaders:528:normalize_ext_rename normalize_ext.filepath=/usr/local/lib/python3.6/dist-packages/nlpia/bigdata/googlenews-vectors-negative300.bin.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-86e84a08a22a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w2v'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nlpia/loaders.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(name, nrows, limit)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mBIG_URLS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m         \u001b[0mfilepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_unzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_filenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nlpia.loaders.get_data.filepaths='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nlpia/loaders.py\u001b[0m in \u001b[0;36mdownload_unzip\u001b[0;34m(names, normalize_filenames, verbose)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mfile_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_ext_rename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'downloaded name={} to filepath={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mfplower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nlpia/loaders.py\u001b[0m in \u001b[0;36mnormalize_ext_rename\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \"\"\"\n\u001b[1;32m    528\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'normalize_ext.filepath='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m     \u001b[0mnew_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_ext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'download_unzip.new_filepaths='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;31m# FIXME: fails when name is a url filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nlpia/futil.py\u001b[0m in \u001b[0;36mnormalize_ext\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'^[.]?([^.]*)\\.([^.]{1,10})*'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'regex pattern = {r}, string={filepath}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfplower\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfplower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnewext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \"\"\"Try to apply the pattern at the start of the string, returning\n\u001b[1;32m    171\u001b[0m     a match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfullmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4-EsZ6TvXmn"
      },
      "source": [
        "import gensim.downloader as api"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HygssXRDwOoB"
      },
      "source": [
        "word_vecs = api.load(\"word2vec-google-news-300\", return_path=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNlLyjbRwd-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e8304f-72a2-48ca-a44f-6075f5209b5d"
      },
      "source": [
        "print(word_vecs)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V84uXkz7yCBd"
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqLX7HJUyH45"
      },
      "source": [
        "word_vectors = KeyedVectors.load_word2vec_format(word_vecs, binary=True, limit=200000)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0aKyQNOyKnJ"
      },
      "source": [
        "def tokenize_and_vectorize(dataset):\n",
        "  tokenizer = TreebankWordTokenizer()\n",
        "  vectorized_data = []\n",
        "  expected = []\n",
        "  for sample in dataset:\n",
        "    tokens = tokenizer.tokenize(sample[1])\n",
        "    sample_vecs = []\n",
        "    for token in tokens:\n",
        "      try:\n",
        "        sample_vecs.append(word_vectors[token])\n",
        "\n",
        "      except KeyError:\n",
        "        pass # No matching token in the Google w2v vocab\n",
        "    \n",
        "    vectorized_data.append(sample_vecs)\n",
        "  return vectorized_data"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIqJ0BID1fXe"
      },
      "source": [
        "def collect_expected(dataset):\n",
        "  \"\"\" Peel of the largest values from the dataset \"\"\"\n",
        "  expected = []\n",
        "  for sample in dataset:\n",
        "    expected.append(sample[0])\n",
        "  return expected"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih3wE5Y62qjl"
      },
      "source": [
        "vectorized_data = tokenize_and_vectorize(dataset)\n",
        "expected = collect_expected(dataset)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4tRGe6C3Lrw"
      },
      "source": [
        "split_point = int(len(vectorized_data)*.8)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFwqMGUO35XQ"
      },
      "source": [
        "X_train = vectorized_data[:split_point]\n",
        "y_train = expected[:split_point]\n",
        "X_test = vectorized_data[split_point:]\n",
        "y_test = expected[split_point:]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQz1G-ID4Xkf"
      },
      "source": [
        "maxlen = 400\n",
        "batch_size = 32\n",
        "embedding_dims = 300\n",
        "filters = 250\n",
        "kernel_size = 3\n",
        "hidden_dims = 250\n",
        "epochs = 2"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xClLUF925jGO"
      },
      "source": [
        "def pad_trunc(data, maxlen):\n",
        "\n",
        "  \"\"\"\n",
        "    For a given dataset pad with zero vectors or truncate to maxlen\n",
        "  \"\"\"\n",
        "\n",
        "  new_data = []\n",
        "\n",
        "  # Create a vector of 0s the length of our word vectors\n",
        "  zero_vector = []\n",
        "  for _ in range(len(data[0][0])):\n",
        "    zero_vector.append(0.0)\n",
        "\n",
        "  for sample in data:\n",
        "    if len(sample) > maxlen:\n",
        "      temp = sample[:maxlen]\n",
        "    elif len(sample) < maxlen:\n",
        "      temp = sample\n",
        "      # Append the appropriate number 0 vectors to the list \n",
        "      additional_elems = maxlen - len(sample)\n",
        "      for _ in range(additional_elems):\n",
        "        temp.append(zero_vector)\n",
        "    \n",
        "    else:\n",
        "      temp = sample\n",
        "    \n",
        "    new_data.append(temp)\n",
        "\n",
        "  return new_data"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYVhfG7wuXzU"
      },
      "source": [
        "X_train = pad_trunc(X_train, maxlen)\n",
        "X_test = pad_trunc(X_test, maxlen)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuzlF2EDvLyi"
      },
      "source": [
        "X_train = np.reshape(X_train, (len(X_train), maxlen, embedding_dims))\n",
        "y_train = np.array(y_train)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5hIe3QGv3oh"
      },
      "source": [
        "X_test = np.reshape(X_test, (len(X_test), maxlen, embedding_dims))\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6kmR1munMfR",
        "outputId": "85951019-325e-4a39-c52c-cff0787c2a13"
      },
      "source": [
        "print(\"Build Model ......\")\n",
        "model = Sequential()\n",
        "\n",
        "# we add a Convolution1D, which will learn filters \n",
        "# word group filters of size filter_length:\n",
        "model.add(Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1, input_shape=(maxlen, embedding_dims)))\n",
        "\n",
        "# we use max pooling:\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# we add a vanila hidden layer:\n",
        "model.add(Dense(hidden_dims))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# we project on a single unit output layer, and squash it with a sigmoid:\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build Model ......\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pJQ8GGmuLBr",
        "outputId": "e9f722c6-ba14-45db-fc2e-7727b33f85ab"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "26/26 [==============================] - 1s 26ms/step - loss: 0.6825 - accuracy: 0.5668 - val_loss: 0.6146 - val_accuracy: 0.6965\n",
            "Epoch 2/2\n",
            "26/26 [==============================] - 0s 16ms/step - loss: 0.5286 - accuracy: 0.7478 - val_loss: 0.5320 - val_accuracy: 0.7164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f63845e2550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF7hWmBaurkF",
        "outputId": "e42a300a-e05a-4916-a5d2-20cb25961c91"
      },
      "source": [
        "model_structure = model.to_json()\n",
        "with open(\"cnn_model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_structure)\n",
        "\n",
        "model.save_weights(\"cnn_weights.h5\")\n",
        "print(\"Model Saved.\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2N1PWWLy0kw"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "with open(\"cnn_model.json\", \"r\") as json_file:\n",
        "  json_string = json_file.read()\n",
        "\n",
        "model = model_from_json(json_string)\n",
        "\n",
        "model.load_weights(\"cnn_weights.h5\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvccTnfdz5hw"
      },
      "source": [
        "sample_1 = \"I'm hate that the dismal weather that had me down for so long, when will it break! Ugh, when does happiness return?  The sun is blinding and the puffy clouds are too thin.  I can't wait for the weekend.\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW-8i9cdz-Kk",
        "outputId": "5a36f4e6-07f9-454b-fbaa-9657d6ef78bf"
      },
      "source": [
        "# We pass a dummy value in the first element of the tuple just because our helper expects it from the way processed the initial data.  That value won't ever see the network, so it can be whatever.\n",
        "vec_list = tokenize_and_vectorize([(1, sample_1)])\n",
        "\n",
        "# Tokenize returns a list of the data (length 1 here)\n",
        "test_vec_list = pad_trunc(vec_list, maxlen)\n",
        "\n",
        "test_vec = np.reshape(test_vec_list, (len(test_vec_list), maxlen, embedding_dims))\n",
        "model.predict(test_vec)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20449972]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuocK8uM0yo8",
        "outputId": "5535b2ce-14b0-4e83-9ad5-620500303e9d"
      },
      "source": [
        "model.predict_classes(test_vec)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-38-77f70a9dfb25>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4MTdBcD09wy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}